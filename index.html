<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Seunghyeok  Back</title>
    <meta name="author" content="Seunghyeok  Back" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="Seunghyeok  Back" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Seunghyeok  Back | about" />
    <meta property="og:url" content="https://seungback.github.io/" />
    <meta property="og:description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="about" />
    <meta name="twitter:description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    
    <meta name="twitter:site" content="@seunghyeokback" />
    <meta name="twitter:creator" content="@seunghyeokback" />

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "Seunghyeok  Back"
        },
        "url": "https://seungback.github.io/",
        "@type": "WebSite",
        "description": "A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
",
        "headline": "about",
        "sameAs": ["https://scholar.google.com/citations?user=N9dLZH4AAAAJ&hl", "https://github.com/seungback", "https://www.linkedin.com/in/seungback", "https://twitter.com/seunghyeokback"],
        "name": "Seunghyeok  Back",
        "@context": "https://schema.org"
      }
    </script>


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üî•</text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://seungback.github.io/">

    <!-- Dark Mode -->
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              
              <!-- Blog -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li> -->

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/CV">curriculum vitae</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <span class="font-weight-bold">Seunghyeok</span>  Back
          </h1>
          <p class="desc">Ph.D. Student @ <a href="#">GIST (Gwangju Institute of Science and Technology)</a>.</p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.png" alt="prof_pic.png">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <p>I am a Ph.D. candidate, advised by Professor <a href="https://ailab.gist.ac.kr/" target="_blank" rel="noopener noreferrer">Kyoobin Lee</a>, at the School of Integrated Technology (Robotics Program), <a href="https://www.gist.ac.kr/" target="_blank" rel="noopener noreferrer">Gwangju Institute of Science and Technology (GIST)</a>, South Korea. I received a B.S. degree in mechanical engineering from GIST, South Korea in 2018.</p>

<p>My research interests are in <em>robot vision for unseen object manipulation</em>. I focused on the robotic perception and manipulation of unseen objects via deep neural networks and Sim2Real transfer. I have developed and integrated various robotic systems, such as <a href="https://github.com/gist-ailab/deep-grasping" target="_blank" rel="noopener noreferrer">vision-based grasping</a>, <a href="https://youtu.be/tPClgvj45vk" target="_blank" rel="noopener noreferrer">furniture assembly from IKEA instruction</a>, and <a href="">human-robot collaboration in an unstructured environment</a>.¬†My research topic also includes the health care application of deep learning in biomedical signals and the image domain.</p>


          </div>

          <!-- News -->          
          <div class="news">
            <h2>news</h2>
            <div class="table-responsive">
              <table class="table table-sm table-borderless"> 
                <tr>
                  <th scope="row">Feb 1, 2022</th>
                  <td>
                    Our work on <a href="https://sites.google.com/view/uoais" target="_blank" rel="noopener noreferrer">unseen object amodal instance segmentation</a> have been accepted at <strong>ICRA 2022</strong>!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 27, 2022</th>
                  <td>
                    üèÖ Won <strong>Bronze prize</strong> at 28th Humantech Paper Award by Samsung Electronics! ($5,000)
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Dec 21, 2021</th>
                  <td>
                    üèÖ Won <strong>Outstanding Paper Award</strong> at ICROS-KROC Honam Conference.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 24, 2021</th>
                  <td>
                    üèÖ Won <strong>Outstanding Paper Award</strong> at KROC 2021.
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>selected publications</h2>
            <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    <img class="img-fluid z-depth-2 rounded" style="object-fit: contain" src="../assets/img/papers/icra2022.png">
    
    <abbr class="badge">ICRA</abbr>
    
  
  </div>

  <div id="back2021unseen" class="col-sm-8">
    
      <div class="title">Unseen Object Amodal Instance Segmentation via Hierarchical Occlusion Modeling</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Back, Seunghyeok</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Joosoon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Taewon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Noh, Sangjun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kang, Raeyoung,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bak, Seongho,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lee, Kyoobin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Accepted at 2022 IEEE International Conference on Robotics and Automation (ICRA 2022)</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2109.11103" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
      
      <a href="https://youtu.be/rDTmXu6BhIU" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a>
      
    
    
    
      <a href="https://github.com/gist-ailab/uoais" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
      <a href="https://sites.google.com/view/uoais" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Instance-aware segmentation of unseen objects is essential for a robotic system in an unstructured environment. Although previous works achieved encouraging results, they were limited to segmenting the only visible regions of unseen objects. For robotic manipulation in a cluttered scene, amodal perception is required to handle the occluded objects behind others. This paper addresses Unseen Object Amodal Instance Segmentation (UOAIS) to detect 1) visible masks, 2) amodal masks, and 3) occlusions on unseen object instances. For this, we propose a Hierarchical Occlusion Modeling (HOM) scheme designed to reason about the occlusion by assigning a hierarchy to a feature fusion and prediction order. We evaluated our method on three benchmarks (tabletop, indoors, and bin environments) and achieved state-of-the-art (SOTA) performance. Robot demos for picking up occluded objects, codes, and datasets are available at https://sites.google.com/view/uoais.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    <img class="img-fluid z-depth-2 rounded" style="object-fit: contain" src="../assets/img/papers/bspc2020.png">
    
    <abbr class="badge">BSPC</abbr>
    
  
  </div>

  <div id="seo2020intra" class="col-sm-8">
    
      <div class="title">Intra-and inter-epoch temporal context network (IITNet) using sub-epoch features for automatic sleep scoring on raw single-channel EEG</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Seo, Hogeon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Back, Seunghyeok</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lee, Seongju,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Park, Deokhwan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Tae,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lee, Kyoobin (first co-author)
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Biomedical Signal Processing and Control</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://www.sciencedirect.com/science/article/pii/S1746809420301932" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
      
      <a href="https://paperswithcode.com/paper/intra-and-inter-epoch-temporal-context" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a>
      
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A deep learning model, named IITNet, is proposed to learn intra- and inter-epoch temporal contexts from raw single-channel EEG for automatic sleep scoring. To classify the sleep stage from half-minute EEG, called an epoch, sleep experts investigate sleep-related events and consider the transition rules between the found events. Similarly, IITNet extracts representative features at a sub-epoch level by a residual neural network and captures intra- and inter-epoch temporal contexts from the sequence of the features via bidirectional LSTM. The performance was investigated for three datasets as the sequence length () increased from one to ten. IITNet achieved the comparable performance with other state-of-the-art results. The best accuracy, MF1, and Cohen‚Äôs kappa () were 83.9%, 77.6%, 0.78 for SleepEDF (‚ÄØ=‚ÄØ10), 86.5%, 80.7%, 0.80 for MASS (‚ÄØ=‚ÄØ9), and 86.7%, 79.8%, 0.81 for SHHS (‚ÄØ=‚ÄØ10), respectively. Even though using four epochs, the performance was still comparable. Compared to using a single epoch, on average, accuracy and MF1 increased by 2.48%p and 4.90%p and F1 of N1, N2, and REM increased by 16.1%p, 1.50%p, and 6.42%p, respectively. Above four epochs, the performance improvement was not significant. The results support that considering the latest two-minute raw single-channel EEG can be a reasonable choice for sleep scoring via deep neural networks with efficiency and reliability. Furthermore, the experiments with the baselines showed that introducing intra-epoch temporal context learning with a deep residual network contributes to the improvement in the overall performance and has the positive synergy effect with the inter-epoch temporal context learning.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    <img class="img-fluid z-depth-2 rounded" style="object-fit: contain" src="../assets/img/papers/icip2020.png">
    
    <abbr class="badge">ICIP</abbr>
    
  
  </div>

  <div id="back2020segmenting" class="col-sm-8">
    
      <div class="title">Segmenting unseen industrial components in a heavy clutter using rgb-d fusion and synthetic data</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Back, Seunghyeok</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Jongwon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kang, Raeyoung,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Choi, Seungjun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lee, Kyoobin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2020 IEEE International Conference on Image Processing (ICIP)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/9190804" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
      
      <a href="https://sigport.org/documents/segmenting-unseen-industrial-components-heavy-clutter-using-rgb-d-fusion-and-synthetic" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a>
      
    
    
    
      <a href="https://github.com/gist-ailab/SF-Mask-RCNN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Segmentation of unseen industrial parts is essential for autonomous industrial systems. However, industrial components are texture-less, reflective, and often found in cluttered and unstructured environments with heavy occlusion, which makes it more challenging to deal with unseen objects. To tackle this problem, we present a synthetic data generation pipeline that randomizes textures via domain randomization to focus on the shape information. In addition, we propose an RGB-D Fusion Mask R-CNN with a confidence map estimator, which exploits reliable depth information in multiple feature levels. We transferred the trained model to real-world scenarios and evaluated its performance by making comparisons with baselines and ablation studies. We demonstrate that our methods, which use only synthetic data, could be effective solutions for unseen industrial components segmentation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%73%68%62%61%63%6B@%67%6D.%67%69%73%74.%61%63.%6B%72" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=N9dLZH4AAAAJ&amp;hl" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/seungback" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/seungback" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/seunghyeokback" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            
            </div>

            <div class="contact-note">
              Feel free to contact by email at <a href="mailto:shback@gm.gist.ac.kr">shback@gm.gist.ac.kr</a>

            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        ¬© Copyright 2022 Seunghyeok  Back. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

